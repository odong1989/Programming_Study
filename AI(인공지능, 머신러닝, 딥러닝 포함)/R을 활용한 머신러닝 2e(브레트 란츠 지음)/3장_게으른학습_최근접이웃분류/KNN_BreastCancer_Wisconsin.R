#책 : R을 활용한 머신러닝(126~140페이지/코딩관련만)
#목표 : KNN클러스터 알고리즘를 활용하여 유방암진단

#KNN클러스터 알고리즘의 장점과 단점(교재115페이지)=======================================
#         KNN클러스터 알고리즘의 장점              |   KNN클러스터 알고리즘의 단점
#--------------------------------------------------+---------------------------------------
#(1)단순하고 효율적이다.                           |(1)모델을 생성하지 않아 특징과 클래스 간의
#(2)기저 데이터 분포에 대한 가정을 않는다.         |   관계를 이해하는 능력이 제약된다.
#(3)훈련 단계가 빠르다.                            |(2)적절한 K의 선택이 필요하다.
#                                                  |(3)분류 단계가 느리다.
#                                                  |(4)명목 특징 및 누락 데이터를 위한 추가처리가 필요하다.
#--------------------------------------------------+---------------------------------------

#KNN클러스터 알고리즘(또는 최근접 이웃방법 기반 알고리즘들)이 게이르다고 하는 이유(교재124페이지)
#최근접 이웃방법에 기반하는 알고리즘들을 '게으른 학습'이라고 한다.
#"엄밀히 말하면 추상화가 일어나지 않기 때문"이라고 설명한다. 
#추상화 및 일반화 단계가 함께 생략되고, 이로 인하여 1장(교재1장인듯?)에서 제시된 학습의 정의가 약화된다.

#완벽주의자가 자신의 엄격한 기준때문에 게으른 사람이 되는 것처럼,
#엄격한 학습의 정의에 의해 어떠한 것도 학습하지 않게 되는 셈이다.
#대신에 훈련 데이터를 글자 그대로 저장하기만 한다.(#최근접 이웃방법 알고리즘이 훈련 단계가 빠른이유.)



#1단계 : 데이터 수집 및 칼럼(열)들 설명.
#책에서 안내한 다운로드 사이트는 UCI머신러닝(http://archive.ics.uci.edu/ml/index.php)
#하지만 나는 캐글관련 사이트(https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)에서 얻어왔다.
#csv파일을 찾는데 UCI는 찾지 못한 관계로...

#총 32개의 칼럼(열)로 식별번호, 암진단(양성음성여부)가 차지한다.
#나머지 30개의 수치 측정치는 디지털화된 세포핵의 데이터이다. 이는 즉 30개의 열들로 구성되고 있다는 것이다.
#
#이 중에서 10개의 특성이 세포핵의 특성을 나타낸다.

#(1)반지름
#질감
#둘레
#넓이
#매끄러움
#조밀성
#오목함
#오목점
#대칭성
#프랙탈 차원





wbcd <-read.csv("C:/sourceTree/Programming_Study/AI(인공지능, 머신러닝, 딥러닝 포함)/R을 활용한 머신러닝 2e(브레트 란츠 지음)/3장_게으른학습_최근접이웃분류/data_BreastCancer_Wisconsin.csv",stringsAsFactors = FALSE)
str(wbcd) #칼럼들을 확인하려면 str()이 더 좋다.

wbcd <-wbcd[-1] #id 삭제(id는 분석에 의미없다.)
str(wbcd) #칼럼들을 확인하려면 str()이 더 좋다.

table(wbcd$diagnosis)#B(양성)이 357개, M(음성)이 212개임을 확인할 수 있다.

wbcd$diagnosis <-factor(wbcd$diagnosis, levels=c("B","M"),
                        labels = c("Benign","Malignant") )


round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)



summary(wbcd[c("radius_mean","area_mean","smoothness_mean")])


#변환 : 수치 데이터 정규화(130~)

normalize <- function(x){
  return ( (x - min(x)) / (max(x) - min(x)) )
}









