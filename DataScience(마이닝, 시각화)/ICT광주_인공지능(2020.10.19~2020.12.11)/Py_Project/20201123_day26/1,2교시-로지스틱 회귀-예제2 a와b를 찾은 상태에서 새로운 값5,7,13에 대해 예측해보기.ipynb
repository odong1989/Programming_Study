{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf_2_3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x,y의 데이터 값\n",
    "data=[[2,0], [4,0], [6,0], [8,1], [10,1], [12,1], [14,1]] # [[공부시간1,합격여부(합격=1) ],[공부시간2,합격여부(합격=1) ]...]\n",
    "x_data = [x_row[0] for x_row in data]\n",
    "y_data = [y_row[1] for y_row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#,a와 b의 값을 임의로 정한다.\n",
    "a = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))\n",
    "b = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y 시그모이드 함수의 방정식을 세운다.\n",
    "y = 1/(1 + np.e** -(a * x_data + b) )#넘파이 라이브러리를 이용하여 작성한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss를 구하는 함수\n",
    "loss = -tf.reduce_mean( np.array(y_data) * tf.log(y) + (1 - np.array(y_data)) * tf.log(1-y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습률 값\n",
    "leaning_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss를 최소로 하는 값 구하기\n",
    "gradient_decent = tf.train.GradientDescentOptimizer(leaning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, loss=4.0817, 기울기a = 2.4706, y절편=-0.3620\n",
      "Epoch : 6000, loss=0.0152, 기울기a = 2.9230, y절편=-20.3114\n",
      "Epoch : 12000, loss=0.0081, 기울기a = 3.5648, y절편=-24.8081\n",
      "Epoch : 18000, loss=0.0055, 기울기a = 3.9564, y절편=-27.5511\n",
      "Epoch : 24000, loss=0.0041, 기울기a = 4.2385, y절편=-29.5268\n",
      "Epoch : 30000, loss=0.0033, 기울기a = 4.4590, y절편=-31.0705\n",
      "Epoch : 36000, loss=0.0028, 기울기a = 4.6399, y절편=-32.3371\n",
      "Epoch : 42000, loss=0.0024, 기울기a = 4.7933, y절편=-33.4107\n",
      "Epoch : 48000, loss=0.0021, 기울기a = 4.9263, y절편=-34.3424\n",
      "Epoch : 54000, loss=0.0019, 기울기a = 5.0439, y절편=-35.1653\n",
      "Epoch : 60000, loss=0.0017, 기울기a = 5.1491, y절편=-35.9020\n",
      "y_test :  [3.88235153e-05]\n",
      "y_test[0] :  3.882351529998951e-05\n",
      "y_test :  [0.53537986]\n",
      "y_test[0] :  0.5353798637638183\n",
      "y_test :  [1.]\n",
      "y_test[0] :  0.9999999999999669\n",
      "\n",
      "y_test : Tensor(\"truediv_35:0\", shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(60001) :\n",
    "        sess.run(gradient_decent)\n",
    "        if i % 6000 ==0 :\n",
    "            print(\"Epoch : %.f, loss=%.4f, 기울기a = %.4f, y절편=%.4f\"\n",
    "                 % (i,sess.run(loss), sess.run(a), sess.run(b) ))\n",
    "\n",
    "        #새로운값 5,7,13에 대한 분석결과를 출력하도록 한다.\n",
    "        if i % 60000 ==0 and i != 0 :\n",
    "            new_x_data=5              \n",
    "            y_test = 1/(1 + np.e** -(a * new_x_data + b) ) \n",
    "            print(\"y_test : \", sess.run(y_test) )             #y_test :  [3.88235153e-05] 의 의미는 합격률=0.0003, 거의 불합격이란애기.              \n",
    "            print(\"y_test[0] : \", sess.run(y_test[0]) )\n",
    "\n",
    "            new_x_data=7\n",
    "            y_test = 1/(1 + np.e** -(a * new_x_data + b) ) # 합격률 0.53537986\n",
    "            print(\"y_test : \", sess.run(y_test) )\n",
    "            print(\"y_test[0] : \", sess.run(y_test[0]) )\n",
    "\n",
    "            new_x_data=13\n",
    "            y_test = 1/(1 + np.e** -(a * new_x_data + b) )  #합격률 1.\n",
    "            print(\"y_test : \", sess.run(y_test) )\n",
    "            print(\"y_test[0] : \", sess.run(y_test[0]) )\n",
    "            print(\"\")\n",
    "            print(\"y_test :\",y_test)\n",
    "            \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
